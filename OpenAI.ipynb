{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CRKbYH2TrlJD",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# LLM\n",
    "\n",
    "\n",
    "Generative AI generates new data based on training samples. It can generate audio, video, image etc as output.\n",
    "\n",
    "Large Language Models(LLM) are foundational machine learning models that use deep learning algorithms to process and understand natural language. These models are trained on massive amount of text data to learn patterns and entity relationships in the language.\n",
    "\n",
    "## Why we call it large language models?\n",
    "Because of size and complexity of neural networks as well as the size of data it is trained on.\n",
    "\n",
    "## Why LLM are so powerful?\n",
    "One model can be used for whole variety of tasks like text generation, chatbot, summarizer etc. So LLM is subset of Deep Learning and have some properties that merge with generative AI.\n",
    "\n",
    "## Few milestones in LLM\n",
    "\n",
    "*  **BERT**: Bidirectional Encoder Representation from Transformers(BERT) was developed by Google\n",
    "* **GPT**: Generative Pre trained Tranformer, developed by Open AI\n",
    "* **XLM**: Cross-Lingual Language model Pretraining by Guillaume Lample, Alexis Conneau\n",
    "* **T5**: Text-to-Text Transfer Transformer, developed by Google AI\n",
    "* **Megatron**: It is large, powerful transformer developed by Research Team by NVIDIA\n",
    "* **M2M-100**: Multi-lingual Encoder decoder (seq-to-seq) model, developed by researcher at Facebook.\n",
    "\n",
    "## How ChatGPT is trained?\n",
    "Internally using LLM whixh is gpt 3.5 or gpt 4. Trained on large amount of data available all over internet.\n",
    "\n",
    "* Generative Pre-training\n",
    "* Supervised Fine-Tuning\n",
    "* Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P2AGGDZVW_ps",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Open AI vs HuggingFace\n",
    "\n",
    "On Hugging Face, every model is avaible. You can use any model irrespective who developed it. But OpenAI is seperate organization on which you can only access models which are developed by OpenAI.\n",
    "\n",
    "\n",
    "OpenAI is leading company in field of AI. It was founded in 2015 as a non profit organization by Sam Altman and Elon Musk. Company was founded with the goal of developing and promoting friendly AI in responsible way.\n",
    "\n",
    "\n",
    "## Tokens\n",
    "Text generation and embeddings models process text in chunks called tokens. Tokens represent commonly occurring sequences of characters. For example, the string \" tokenization\" is decomposed as \" token\" and \"ization\", while a short and common word like \" the\" is represented as a single token. Note that in a sentence, the first token of each word typically starts with a space character. As a rough rule of thumb, 1 token is approximately 4 characters or 0.75 words for English text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUAMKjpIo8T_"
   },
   "source": [
    "## OpenAI models\n",
    "\n",
    "* **GPT4-o**: It is multimodel(accept image or text as input and give text as output). It has same intelligence level as GPT4 but it is more efficient. It generate text 2x faster and 50% cheaper.Trained on data till Oct 2023.\n",
    "* **GPT4-turbo and GPT4**: GPT-4 is a large multimodal model  that can solve difficult problems with greater accuracy than any of our previous models, thanks to its broader general knowledge and advanced reasoning capabilities.\n",
    "\n",
    "* **GPT3.5-turbo**: GPT-3.5 Turbo models can understand and generate natural language or code and have been optimized for chat.\n",
    "* **DALL-E**: DALL·E is a AI system that can create realistic images and art from a description in natural language. DALL·E 3 currently supports the ability, given a prompt, to create a new image with a specific size. DALL·E 2 also support the ability to edit an existing image, or create variations of a user provided image.\n",
    "* **TTS**: TTS is an AI model that converts text to natural sounding spoken text. We offer two different model variates, tts-1 is optimized for real time text to speech use cases and tts-1-hd is optimized for quality.\n",
    "* **Whisper**: Whisper is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multi-task model that can perform multilingual speech recognition as well as speech translation and language identification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55Ajhq-vs3Gx",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Text Generation Models\n",
    "OpenAI's text generation models (often called generative pre-trained transformers or large language models) have been trained to understand natural language, code, and images. The models provide text outputs in response to their inputs. The text inputs to these models are also referred to as \"prompts\".\n",
    "\n",
    "Designing a prompt is essentially how you “program” a large language model model, usually by providing instructions or some examples of how to successfully complete a task.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2R9QpZ6lnxhb"
   },
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is OpenAI API?\n",
    "This openAI API is designed to provide developers a seemless access to state of the art, pretrained, AI models like gpt3.5, wispher, etc. By using API you can add cutting edge capabilities to your application. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
